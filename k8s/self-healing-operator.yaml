apiVersion: v1
kind: ServiceAccount
metadata:
  name: self-healing-operator
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: self-healing-operator
rules:
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets"]
  verbs: ["get", "list", "watch", "update", "patch"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch", "delete"]
- apiGroups: [""]
  resources: ["services"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["autoscaling"]
  resources: ["horizontalpodautoscalers"]
  verbs: ["get", "list", "watch", "create", "update", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: self-healing-operator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: self-healing-operator
subjects:
- kind: ServiceAccount
  name: self-healing-operator
  namespace: default
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: self-healing-operator
spec:
  replicas: 1
  selector:
    matchLabels:
      app: self-healing-operator
  template:
    metadata:
      labels:
        app: self-healing-operator
    spec:
      serviceAccountName: self-healing-operator
      containers:
      - name: self-healing-operator
        image: python:3.11-slim
        command: ["python3"]
        args: ["-c", "
import time
import requests
import json
import subprocess
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SelfHealingOperator:
    def __init__(self):
        self.ai_service_url = 'http://ai-anomaly-detection:8083'
        self.check_interval = 30  # seconds
        
    def check_anomalies(self):
        try:
            response = requests.get(f'{self.ai_service_url}/fetch-metrics', timeout=10)
            if response.status_code == 200:
                metrics = response.json()
                # Check for anomalies and trigger healing actions
                self.analyze_metrics(metrics)
        except Exception as e:
            logger.error(f'Error checking anomalies: {e}')
    
    def analyze_metrics(self, metrics):
        # Simple heuristic-based healing
        # In a real implementation, this would use ML models
        logger.info('Analyzing metrics for anomalies...')
        
        # Example: Scale up if high CPU usage detected
        # This is a simplified example - real implementation would be more sophisticated
        
    def restart_failed_pods(self):
        try:
            result = subprocess.run(['kubectl', 'get', 'pods', '--field-selector=status.phase=Failed', '-o', 'json'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                pods = json.loads(result.stdout)
                for pod in pods.get('items', []):
                    logger.info(f'Restarting failed pod: {pod[\"metadata\"][\"name\"]}')
                    subprocess.run(['kubectl', 'delete', 'pod', pod['metadata']['name']])
        except Exception as e:
            logger.error(f'Error restarting failed pods: {e}')
    
    def scale_service(self, service_name, replicas):
        try:
            subprocess.run(['kubectl', 'scale', 'deployment', service_name, f'--replicas={replicas}'])
            logger.info(f'Scaled {service_name} to {replicas} replicas')
        except Exception as e:
            logger.error(f'Error scaling {service_name}: {e}')
    
    def run(self):
        logger.info('Self-healing operator started')
        while True:
            try:
                self.check_anomalies()
                self.restart_failed_pods()
                time.sleep(self.check_interval)
            except KeyboardInterrupt:
                break
            except Exception as e:
                logger.error(f'Error in main loop: {e}')
                time.sleep(self.check_interval)

if __name__ == '__main__':
    operator = SelfHealingOperator()
    operator.run()
"]
        env:
        - name: PYTHONUNBUFFERED
          value: "1"
        volumeMounts:
        - name: kubectl-config
          mountPath: /root/.kube
      volumes:
      - name: kubectl-config
        configMap:
          name: kubectl-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubectl-config
data:
  config: |
    apiVersion: v1
    kind: Config
    clusters:
    - cluster:
        server: https://kubernetes.default.svc
      name: default
    contexts:
    - context:
        cluster: default
        user: default
      name: default
    current-context: default
    users:
    - name: default
      user: {}
